---
title: "automatization_notebook_04"
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(stringi)
library(here)
library(flextable)
library(gtsummary)
library(ggplot2)
library(purrr)
library(gridExtra)
```

# Чтение данных

В вашем варианте нужно использовать датасет healthcare-dataset-stroke-data.

```{r}
path <- here('data', 'raw','healthcare-dataset-stroke-data.csv')
df <- read_csv(path)


```

# Выведите общее описание данных

```{r}

head(df)

```

# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

**Обоснование**: 

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4) Отсортируйте данные по возрасту по убыванию;

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6) Присвойте получившийся датасет переменной "cleaned_data".

```{r}
df <- df %>%
  mutate(id = as.character(id), bmi = as.numeric(bmi)) %>% 
  mutate(across(c(gender, hypertension, heart_disease, ever_married, work_type, Residence_type, smoking_status, stroke), as.factor))# Приведение к нужному типу
  
cleaned_data <- df %>% select(where(~ (sum(is.na(.)) / nrow(df)) < 0.2)) %>% # Отбор и удаление столбцов,  в которых пропущенных значений более 20%
  filter(rowSums(is.na(.)) < length(df) * 0.2) %>% # Отбор и удаление строк, в которых пропущенных значений более 20%. Т.к. количество пропущенных значений и в столюцах и строках было менее 20%, данные не изменились 
  rename_with(function(x) x %>% stri_replace_all_regex("_", " ", vectorize_all = F)) %>% # Переименование
  arrange(desc(age)) # Сортировка данных по возрасту по убыванию
  
```

# Сколько осталось переменных?

```{r}
cleaned_data %>% glimpse()
print(paste('Осталось', length(cleaned_data), 'переменных'))


```

# Сколько осталось случаев?

```{r}
cleaned_data %>% glimpse() 
print(paste('Осталось', nrow(cleaned_data), 'случаев'))


```

# Есть ли в данных идентичные строки?

```{r}
duplicates <- cleaned_data %>% filter(duplicated(.))
print(paste('Идентичных строк', nrow(duplicates)))
```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}

missing_var <- cleaned_data %>%
  summarise_all(~ sum(is.na(.))) %>%
  gather('Переменные', 'Пропущенные значения') 

missing_var

```

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (stroke):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}
statistics <- list(
      `Количество субъектов` = ~length(.x) %>% as.character(),
      `Количество (есть данные)` = ~sum(!is.na(.x)) %>% as.character(),
      `Нет данных` = ~sum(is.na(.x)) %>% as.character(),
      `Ср. знач.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `95% ДИ для среднего` = ~sd(.x, na.rm = TRUE) %>% round(2) %>% as.character(),
      `мин. - макс.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(min(.x, na.rm = TRUE) %>% round(2), " - ", max(.x, na.rm = TRUE) %>% round(2))),
      `Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
      `Q1 - Q3` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(quantile(.x, 0.25, na.rm = TRUE) %>% round(2), " - ", quantile(.x, 0.75, na.rm = TRUE) %>% round(2)))
)

cleaned_data %>% select(stroke, where(is.numeric)) %>% 
  group_by(stroke) %>% 
  summarise(across(where(is.numeric), statistics)) %>% 
  pivot_longer(!stroke) %>% 
  separate(name, into = c('Переменная','Статистика'), sep = '_') %>% 
  rename('Значения' = value) %>% 
  flextable()
  

```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (stroke):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}
cleaned_data %>% 
  select(stroke, where(is.factor)) %>% 
  tbl_summary(by = stroke) %>% 
  add_ci()
```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r}
numeric_columns <- cleaned_data %>%
  select(where(is.numeric))

plots <- map(names(numeric_columns), function(var) {
  ggplot(cleaned_data, aes_string(x = "stroke", y = paste0("`", var, "`"), group = "stroke")) +
    geom_boxplot(aes(color = stroke)) + 
    geom_point(aes(color = stroke), position = position_jitter(width = 0.03), alpha = 0.05) +
    scale_color_brewer(type = 'div', palette = 'Set2') +
    labs(x = "stroke", y = var) +
    ggtitle(paste("Boxplot of", var))
})

grid.arrange(grobs = plots, ncol = 2)

```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}
categorical_columns <- cleaned_data %>%
  select(where(is.factor))

bars <- map(names(categorical_columns), function(var) {
  ggplot(cleaned_data, aes_string(x = "stroke", fill = sprintf("`%s`", var))) +
    geom_bar(position = "dodge") +
    labs(x = "stroke", y = "Frequency", fill = var) +
    ggtitle(paste("Distribution of", var, "by stroke"))
})

bars

# Выбор оптимального способа визуализации категориальных переменных зависит от задачи, которую мы решаем. Выбор в пользу столбчатой диаграммы был сделан в силу хорошей демонстации распределения переменных в группах.

```


# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
# Тест Шапиро-Уилка имеет ограничение при применении на выборке <3 и > 5000, поскольку даже незначительные отклонения от нормальности будут квалифицироваться как значимые на обычных уровнях, следовательно тест Шапиро-Уилка в данном случае для всех количественных переменных будет <0.05.

```

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}
numeric_columns <- cleaned_data %>%
   select(where(is.numeric))

qq_plots <- lapply(names(numeric_columns), function(var) {
  ggplot(cleaned_data, aes(sample = .data[[var]])) +
    geom_qq() +
    labs(title = paste("Q-Q Plot of", var))
})

print(qq_plots)

# Ни один метод не подтверждает нормальность окончательно, и у разных методов есть свои преимущества и ограничения. Визуальные методы нагляднее для быстрой оценки характера распределения, а также не имеют ограничений по размеру выборкм.
#Распеределение возраста является равномерным и напоминает распределение Стьюдента. Ср. уровень глю имеет двугорбое распределение, а ИМТ напоминает экспоненциальное распределение. 
```

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Напишите текст здесь**
1. Тест Колмогорова-Смирнова. 
Ограничения: он может быть чувствителен к размеру выборки, критерий требует, чтобы выборка была достаточно большой и лучше подходит для непрерывных данных.
2. Тест Лиллиефорса.
Ограничения: он тоже чувствителен к размеру выборки и требует, чтобы выборка была достаточно большой.
3. Оценка распределения с помощью гистограмм. 
Ограничения: нет колическтвенной оценки, субъективная интерпретация,внешний вид может меняться в зависимости от выбранного интервала.
4. Коэффициенты ассиметрии и эксцесса. 
Ограничения: не учитывают плотность распределения, мультиможальность.

## Сравнение групп

1) Сравните группы (переменная **stroke**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}
cleaned_data %>% 
  select(!id) %>% 
  tbl_summary(by = stroke) %>% 
  add_p(list(all_continuous() ~ "t.test", all_categorical() ~ "fisher.test"))
#  При проведении тестов Хи-квадрат, если ожидаемое количество наблюдений в одном из ячеек меньше 5, точный тест Фишера предпочтительнее.
# Для сравнения средних в группах используется  Welch Two Sample t-test, который позволяет сравнивать группы с неравными дисперсиями. Учитывая большой обхем выборки тест должен быть устойчив от отклонений от нормальности.

```

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}



```

## Моделирование

1) Постройте регрессионную модель для переменной **stroke**. Опишите процесс построения

```{r}




